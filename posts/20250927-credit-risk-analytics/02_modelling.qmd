---
title: "Modelling Credit Risk"
author: "Aleksei Prishchepo"
date: "2025-09-17"
fig-format: svg
number-sections: true
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    highlight-style: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.width = 8, fig.height = 6)

library(tidyverse)
library(caret)
library(pROC)
library(PRROC)
library(randomForest)
library(xgboost)
library(vip)       # for variable importance plots
library(janitor)

```

## Load Data

Let's load saved data.

```{r load-data}
dataset <- read.csv("data_selected.csv", row.names=NULL)
dataset <- dataset |> 
  mutate(across(where(is.character), as.factor))
glimpse(dataset)
```

## Preprocess Data

We will split data into train and test sets.

```{r preprocess-data}
set.seed(123)
train_index <- createDataPartition(dataset$loan_status, p = 0.7, list = FALSE)
train <- dataset[train_index, ]
test  <- dataset[-train_index, ]
```

## Logistic Regression

We're going to use selected at the previous step variables.

```{r logistic-regression}
glm_model <- glm(loan_status ~ .,
  family = "binomial", data = train
)
summary(glm_model)
```

```{r glm-evaluation}

glm_probs <- predict(glm_model, newdata = test, type = "response")

glm_pred <- ifelse(glm_probs > 0.5, "Yes", "No") |>
  factor(levels = c("No","Yes"))

# Confusion matrix
confusionMatrix(glm_pred, test$loan_status)

```

```{r glm-roc-curve}

# ROC curve
roc_glm <- roc(response = test$loan_status, predictor = glm_probs, levels = c("No","Yes"))
plot(roc_glm, col = "blue", main = "ROC Curve - Logistic Regression")
auc(roc_glm)

```

## Random Forest

The next model we'll try is Random Forest. It is not interpretable
except for variable importance, but often performs better than logistic
regression.

We will use full set of variables here since Random Forest can handle
correlated features well.

```{r load-full-data}
dataset <- read.csv("data_cleaned.csv", row.names=NULL)

# Remove not independent variables
dataset <- dataset |> select(-c(loan_int_rate, loan_grade))

dataset <- dataset |> 
  mutate(across(where(is.character), as.factor))
dataset <- dataset |> mutate(loan_status = ifelse(loan_status == 0, "No", "Yes"))
dataset <- dataset |> mutate(loan_status = factor(loan_status, levels = c("No","Yes")))
glimpse(dataset)

set.seed(123)

train_index <- createDataPartition(dataset$loan_status, p = 0.7, list = FALSE)
train <- dataset[train_index, ]
test  <- dataset[-train_index, ]
```

```{r random-forest}
set.seed(123)
rf_model <- randomForest(
  train |> select(-loan_status), train$loan_status,
  data = train, ntree = 100, importance = TRUE
)

# Predictions
rf_probs <- predict(rf_model, newdata = test, type = "prob")[, 2]
rf_pred <- predict(rf_model, newdata = test)
```

### Confusion matrix

```{r rf-evaluation}
confusionMatrix(rf_pred, test$loan_status)
```

### ROC curve

```{r rf-roc-curve}
roc_rf <- roc(test$loan_status, rf_probs, levels = c("No", "Yes"))
plot(roc_glm, col = "blue")
plot(roc_rf, col = "darkgreen", add = TRUE)
legend("bottomright", legend = c("Logistic Regression", "Random Forest"),
       col = c("blue", "darkgreen"), lwd = 2)
auc(roc_rf)
```

### Variable importance

```{r rf-variable-importance}
varImpPlot(rf_model)
```

```{r rf-variable-importance-vip}
rf_model$importance 
```

To simplify the model we can use only the most important variables. Both
metrics (Mean Decrease Accuracy and Mean Decrease Gini) show that the
least important variables are `gender`, `marital_status`,
`education_level`, `cb_person_cred_hist_length`, `country`,
`credit_utilization_ratio`, `employment_type`, `loan_term_months`,
`open_accounts`, and `past_delinquencies`. The `state` is shadowed by
`city` so we can drop it as well.

Let's drop them, retrain the model, and see if the performance changes.

```{r random-forest-simplified}
set.seed(123)

train <- train |> select(-c(
  gender, marital_status, education_level, cb_person_cred_hist_length,
  country, credit_utilization_ratio, employment_type, loan_term_months,
  open_accounts, past_delinquencies, state
))
test <- test |> select(-c(
  gender, marital_status, education_level, cb_person_cred_hist_length,
  country, credit_utilization_ratio, employment_type, loan_term_months,
  open_accounts, past_delinquencies, state
))
rf_model <- randomForest(
  train |> select(-loan_status), train$loan_status,
  data = train, ntree = 100, importance = TRUE
)

# Predictions
rf_probs <- predict(rf_model, newdata = test, type = "prob")[, 2]
rf_pred <- predict(rf_model, newdata = test)

# Confusion matrix
confusionMatrix(rf_pred, test$loan_status)
# AUC-ROC 
roc_rf <- roc(test$loan_status, rf_probs, levels = c("No", "Yes"))
auc(roc_rf)
```

The model performance remains roughly the same or even improves, so we
will use the simplified set of variables for the next model as well.

## XGBoost

The last model we'll try is XGBoost. It often provides the best
performance but lacks interpretability.

```{r xgboost}
# Prepare data
x_train <- train |>
  mutate(loan_status = ifelse(loan_status == "Yes", 1, 0))

x_test <- test |>
  mutate(loan_status = ifelse(loan_status == "Yes", 1, 0))

x_test <- cbind(x_test, model.matrix(~ . - 1, data = x_test |> select(where(is.factor)) ))

x_test <- x_test |> select(-where(is.factor))

x_train <- cbind(x_train, model.matrix(~ . - 1, data = x_train |> select(where(is.factor))))
x_train <- x_train |> select(-where(is.factor))

dtrain <- xgb.DMatrix(
  data = as.matrix(select(x_train, -loan_status)),
  label = x_train$loan_status
)
dtest <- xgb.DMatrix(
  data = as.matrix(select(x_test, -loan_status)),
  label = x_test$loan_status
)
# Train
params <- list(
  objective = "binary:logistic",
  eval_metric = "auc"
)

xgb_model <- xgb.train(
  params = params, data = dtrain, nrounds = 200,
  watchlist = list(train = dtrain, test = dtest),
  verbose = 0
)

# Predictions
xgb_probs <- predict(xgb_model, dtest)
roc_xgb <- roc(x_test$loan_status, xgb_probs)


plot(roc_glm, col = "blue")
plot(roc_rf, col = "darkgreen", add = TRUE)
plot(roc_xgb, col = "red", add = TRUE)
legend("bottomright",
  legend = c("Logistic Regression", "Random Forest", "XGBoost"),
  col = c("blue", "darkgreen", "red"), lwd = 2
)
auc(roc_xgb)

```

```{r xgb-variable-importance-vip}

# Feature importance
vip(xgb_model, num_features = 15)
```

```{r xgb-variable-importance}
xgb.importance(model = xgb_model)
```

## Precision-Recall Curves

```{r fig-precision-recall-glm}
# Logistic regression PR curve
pr_glm <- pr.curve(
  scores.class0 = glm_probs[test$loan_status == "Yes"],
  scores.class1 = glm_probs[test$loan_status == "No"], curve = TRUE
)
plot(pr_glm, main = "Precision-Recall Curve (GLM)")
```

```{r fig-precision-recall-rf}
# Random forest PR curve
pr_rf <- pr.curve(
  scores.class0 = rf_probs[test$loan_status == "Yes"],
  scores.class1 = rf_probs[test$loan_status == "No"], curve = TRUE
)
plot(pr_rf, main = "Precision-Recall Curve (RF)")
```

```{r fig-precision-recall-compare}
pr_xgb <- pr.curve(
  scores.class0 = xgb_probs[x_test$loan_status == 1],
  scores.class1 = xgb_probs[x_test$loan_status == 0], curve = TRUE
)
plot(pr_xgb, main = "Precision-Recall Curve (XGBoost)")
```
